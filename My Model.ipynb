{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset\n",
    "the MNIST dataset is a database of 60,000 training images and 10,000 test images of handwritten digits that is commonly used for training and testing in the field of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing neccesary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is available in Keras' built in 'dataset' library already, meaning we simply need to import it. We will also import a number of other libraries such as numpy, matplotlib and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras as kr\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training and test dataset\n",
    "MNIST will give us two tuples. The first tuple is the training set and the second is the test set.\n",
    "\n",
    "\n",
    "#### Now we should normalise the data\n",
    "\n",
    "This basically means we want to scale it down between 0 and 1 which makes it easier for the network to process. It's important to note that the distance between each value is still the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train) , (X_test, y_test) = mnist.load_data() # Load datasets\n",
    "\n",
    "X_train = kr.utils.normalize(X_train, axis=1) # Normalize x train and test sets\n",
    "X_test = kr.utils.normalize(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the shape of each dataset\n",
    "We can print the shape of the data in each dataset to confirm the number of images and the shape of each image. We see here that we have 60'000 images in our training set and each image is 28 pixels x 28. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the first image of the X_train dataset\n",
    "Now we can plot the first image of the x_train dataset using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, ' Digit 5')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], plt.cm.binary) # this is not a color image so we use colormap to change it to black and white\n",
    "plt.title(\" Digit \" + str(y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is an array of the actual data we want to pass through our neural network.\n",
    "\n",
    "Below, the 0's in the array repersent the blank space in the image and the numbers ranging from 0.01-0.99 represent the pencil stroke of the digit.\n",
    "\n",
    "Before normalisation these numbers would have ranged between 0-255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00393124, 0.02332955, 0.02620568,\n",
       "        0.02625207, 0.17420356, 0.17566281, 0.28629534, 0.05664824,\n",
       "        0.51877786, 0.71632322, 0.77892406, 0.89301644, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05780486, 0.06524513,\n",
       "        0.16128198, 0.22713296, 0.22277047, 0.32790981, 0.36833534,\n",
       "        0.3689874 , 0.34978968, 0.32678448, 0.368094  , 0.3747499 ,\n",
       "        0.79066747, 0.67980478, 0.61494005, 0.45002403, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12250613, 0.45858525, 0.45852825,\n",
       "        0.43408872, 0.37314701, 0.33153488, 0.32790981, 0.36833534,\n",
       "        0.3689874 , 0.34978968, 0.32420121, 0.15214552, 0.17865984,\n",
       "        0.25626376, 0.1573102 , 0.12298801, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04500225, 0.4219755 , 0.45852825,\n",
       "        0.43408872, 0.37314701, 0.33153488, 0.32790981, 0.28826244,\n",
       "        0.26543758, 0.34149427, 0.31128482, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.1541463 , 0.28272888,\n",
       "        0.18358693, 0.37314701, 0.33153488, 0.26569767, 0.01601458,\n",
       "        0.        , 0.05945042, 0.19891229, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.0253731 ,\n",
       "        0.00171577, 0.22713296, 0.33153488, 0.11664776, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20500962, 0.33153488, 0.24625638, 0.00291174,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01622378, 0.24897876, 0.32790981, 0.10191096,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04586451, 0.31235677, 0.32757096,\n",
       "        0.23335172, 0.14931733, 0.00129164, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.10498298, 0.34940902,\n",
       "        0.3689874 , 0.34978968, 0.15370495, 0.04089933, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06551419,\n",
       "        0.27127137, 0.34978968, 0.32678448, 0.245396  , 0.05882702,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02333517, 0.12857881, 0.32549285, 0.41390126, 0.40743158,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32161793, 0.41390126, 0.54251585,\n",
       "        0.20001074, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.06697006,\n",
       "        0.18959827, 0.25300993, 0.32678448, 0.41390126, 0.45100715,\n",
       "        0.00625034, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.05110617, 0.19182076, 0.33339444,\n",
       "        0.3689874 , 0.34978968, 0.32678448, 0.40899334, 0.39653769,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04117838, 0.16813739, 0.28960162, 0.32790981, 0.36833534,\n",
       "        0.3689874 , 0.34978968, 0.25961929, 0.12760592, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.04431706, 0.11961607,\n",
       "        0.36545809, 0.37314701, 0.33153488, 0.32790981, 0.36833534,\n",
       "        0.28877275, 0.111988  , 0.00258328, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.05298497, 0.42752138, 0.4219755 , 0.45852825,\n",
       "        0.43408872, 0.37314701, 0.33153488, 0.25273681, 0.11646967,\n",
       "        0.01312603, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.37491383,\n",
       "        0.56222061, 0.66525569, 0.63253163, 0.48748768, 0.45852825,\n",
       "        0.43408872, 0.359873  , 0.17428513, 0.01425695, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.92705966,\n",
       "        0.82698729, 0.74473314, 0.63253163, 0.4084877 , 0.24466922,\n",
       "        0.22648107, 0.02359823, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we are ready to build our model\n",
    "\n",
    "A sequential model is a linear stack of layers. We make our input layer flatten the data being passed to it. This is neccesary because our images are 28x28 multi-dimensional arrays which we do not want.\n",
    "\n",
    "Our next two layers are dense layers. A dense layer is just a regular layer of neurons in a neural network. Each neuron recieves input from all the neurons in the previous layer, thus densely connected. We pass them two parameters; how many neurons in the layer and the activasion function.\n",
    "\n",
    "Our final layer has 10 neurons specified as our input data ranges from 0-9 and our activation function is softmax for probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kr.models.Sequential() # Create a new sequential neural network\n",
    "model.add(kr.layers.Flatten()) # Input layer\n",
    "model.add(kr.layers.Dense(128, activation=\"relu\")) # 128 neurons and the 'basic' activation function.\n",
    "model.add(kr.layers.Dense(128, activation=\"relu\"))\n",
    "model.add(kr.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling and train our model\n",
    "Here we pass 3 parameters; the optimizer to use, the loss metric (the degree of error) and the metrics to track.\n",
    "\n",
    "To train the model we use the fit function. We pass in what we want trained and the epochs. The epochs is simply how many times we want our neural network to go over the training data set. If we set it to 1, the neural network will get to see the data once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.2683 - accuracy: 0.9209\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.1153 - accuracy: 0.9647\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0838 - accuracy: 0.9751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2007999fc48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"]) # Played around with 'sgd' and 'adam' optimizer also.\n",
    "\n",
    "model.fit(X_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate validation loss and accuracy\n",
    "Next we should calculate our validatio loss and accuracy. This is where the test sets come in. To do this we use the evaluate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 43us/step\n",
      "0.10735147973909043 0.97079998254776\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.6741379e-14 3.3100953e-10 4.7683059e-08 ... 9.9999487e-01\n",
      "  3.8514379e-11 2.4859915e-08]\n",
      " [2.9361364e-15 4.6006483e-07 9.9999952e-01 ... 3.0596628e-15\n",
      "  4.5170017e-11 1.2124604e-18]\n",
      " [1.7375894e-09 9.9956495e-01 2.8982261e-06 ... 4.6373432e-05\n",
      "  3.7657583e-04 4.0445423e-07]\n",
      " ...\n",
      " [5.9882494e-12 1.1096398e-07 3.6240856e-08 ... 2.7119202e-05\n",
      "  1.2328362e-05 3.2770127e-04]\n",
      " [5.7920901e-11 1.5732864e-09 1.9108130e-10 ... 2.8638847e-09\n",
      "  1.6291812e-04 1.3011457e-11]\n",
      " [1.4109174e-10 1.8653339e-13 5.5967020e-10 ... 2.7849362e-14\n",
      "  1.2085699e-10 5.7522810e-12]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "i = random.randint(1, 101)\n",
    "    \n",
    "np.argmax(predictions[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQnklEQVR4nO3de4xc5X3G8e+Dd33BF/AFG2MjTIgh0BBMWMzFqARRKJhWJpFKcavIqCSmVVAhyh8hqVSIKiFKQlKqRkEmWJgoEGgDwmlJAnUSSFrisljGGAw1FwOLjY0vZW2D7V3vr3/sgNZmzrvruXvf5yOtdub85sz5MezjMzPvOedVRGBmw98RzW7AzBrDYTfLhMNulgmH3SwTDrtZJhx2s0w47JmT9HNJi2r9WGs98jj78CUpgPeBAPYCq4ElEfFgDZ77GuBLEXFB4jHfARYAxwJvA7dGxH3Vbtsq4z378HdGRIwDTgHuBf5F0s0N2vZu4E+Bo4BFwJ2Szm/Qtu0gDnsmImJrRPwI+BvgG5ImA0j6jaQvlW6PkHSHpK2SXpd0vaSQ1DbwsZJOBe4CzpO0S9L/FWzz5oh4KSL6ImIl8FvgvEb899rHOez5eRRoA+aWqX0ZuByYA3wWuLLcE0TEOuCvgacjYlxEHD3YRiWNAc4GXqiwb6uSw56ZiOgBtgKTypSvAu6MiK6I2AHcVsNN3wU8B/yyhs9ph6Ct2Q1YY0lqB44BtpcpHwe8NeD+W2UeU8k2vw18Grgo/I1w0zjs+VkA9AL/U6a2CZg54P7xiecZUmglfYv+jwYXRkT3UJu02vPb+ExImiTpL4HvA/8YEdvKPOwh4AZJMyQdDXw98ZSbgZmSRia2+Q3gL4BLCrZnDeQ9+/D3XGm8fR/9n5m/GhH3Fzz2buBkYA3QDfwz8Dlgf5nH/or+L9vekdQXEVPKPObW0nbXS/poWUTcWuF/i1XBB9VYIUmXA3dFxAnN7sWq57fx9hFJYyTNl9QmaQZwM/BIs/uy2vCe3T4i6UjgSeBTwAfAfwA3+Iu14cFhN8uE38abZaKh38aP1KgYzdhGbtIsK3vYzb7Yq3K1qsIu6TLgTmAE8MOISB5eOZqxnKOLq9mkmSWsjBWFtYrfxksaQf8BGpcDpwELJZ1W6fOZWX1V85l9LvBKRLwWEfuAn9B/KKaZtaBqwj6DA0+U6CotO4CkxZI6JXX2sLeKzZlZNaoJe7kvAT42jhcRSyKiIyI62hlVxebMrBrVhL2LA8+KmglsrK4dM6uXasL+DDBb0omlM5+uBpbXpi0zq7WKh94iolfS9fRfeWQEsDQifMkhsxZV1Th7RDwGPFajXsysjny4rFkmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZaKhUzYPVyP+4JRkfdOFk5P1PRftTNbHH7knWZ84+oPCWvuI/cl129SXrB8zeleyfvLYd5L1H74wr7A2/vH09N1T7ns2WY+efcm6Hch7drNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJh90sEx5nH6LUWPqGb7Un1x0zamu6Hqqopw/1Ubz+xu4JyXV7n0wfA7Dm9L3J+pvHT0zWTzxmW2Gt64r0MQCvzT4rWT/p/h3Jet+al5L13FQVdkkbgJ3AfqA3Ijpq0ZSZ1V4t9uwXRUR612VmTefP7GaZqDbsATwu6VlJi8s9QNJiSZ2SOntIf/4zs/qp9m38vIjYKGkq8ISklyLiqYEPiIglwBKACZoUVW7PzCpU1Z49IjaWfm8BHgHm1qIpM6u9isMuaayk8R/eBi4F1taqMTOrrWrexk8DHpH04fPcHxG/qElXLWj/2JGFtTGj6vtdRAwyDv/quuMKa6d+e2Ny3d43Xq6op6E64uSTCmttf3xUct2eC9Ln0m/4wqRkfdbr4wtrfTvT1xAYjioOe0S8BpxRw17MrI489GaWCYfdLBMOu1kmHHazTDjsZplQROMOapugSXGOLm7Y9hpl7+VnJ+sbL6zuQMVZPyu+VDSA/mt1Vc/fNEoPKb573bnJ+t5LupP1tt8WD+0d+0//nVz3cLUyVtAd28u+sN6zm2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZ8Di7tSy1pY9PeP3m9PENPccXT+k89sVRyXWPu/3wHIf3OLuZOexmuXDYzTLhsJtlwmE3y4TDbpYJh90sE56y2VpW9PYm6xNfSh8jsu2k4imh5y9Mj6Ovvj1ZPix5z26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZcLj7HbYmrRqW7K+7YqxDerk8DDonl3SUklbJK0dsGySpCckrS/9nljfNs2sWkN5G38vcNlBy24CVkTEbGBF6b6ZtbBBwx4RTwHbD1q8AFhWur0MuLLGfZlZjVX6Bd20iNgEUPo9teiBkhZL6pTU2cPeCjdnZtWq+7fxEbEkIjoioqOd9EX+zKx+Kg37ZknTAUq/t9SuJTOrh0rDvhxYVLq9CHi0Nu2YWb0MZejtAeBp4BRJXZKuBW4DLpG0HrikdN/MWtigB9VExMKCkmd7MDuM+HBZs0w47GaZcNjNMuGwm2XCYTfLhE9xtcPWtrOnDPKIDxrSx+HCe3azTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMeZ7fD1q4Zqnjdf3/o/GR9JukpnQ9H3rObZcJhN8uEw26WCYfdLBMOu1kmHHazTDjsZpnwOLu1rCNGj07W9x0V6SfoGlNYOuHul5Or7k8/82HJe3azTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMeZ7emUVv6z++9BXOS9ZGzu5P1/S9MKK5t3ZZcdzgayvzsSyVtkbR2wLJbJL0taXXpZ3592zSzag3lbfy9wGVlln8vIuaUfh6rbVtmVmuDhj0ingK2N6AXM6ujar6gu17SmtLb/IlFD5K0WFKnpM4e9laxOTOrRqVh/wFwEjAH2ATcUfTAiFgSER0R0dHOqAo3Z2bVqijsEbE5IvZHRB9wNzC3tm2ZWa1VFHZJ0wfc/TywtuixZtYaBh1nl/QA8DlgiqQu4Gbgc5LmAAFsAK6rY482TGnkyGR92xfeT9YH++Od+St/RzTQoGGPiIVlFt9Th17MrI58uKxZJhx2s0w47GaZcNjNMuGwm2XCp7jWwhEj0uXTT07Wt5xzdLI+7aEXk/W+3R8U1qJnX3LdelN78fDaq39/Rnpddifr7b85Klkf8eTTyXpuvGc3y4TDbpYJh90sEw67WSYcdrNMOOxmmXDYzTLhcfYhGnFa8Vj5+msmJ9edcGr6ssUR6Uv8bV0wNVl/963Cq4Jx5Jvp/8WjdqSnPZ66dFWyHnvTp5Fu/NuOwtrIk99Lrvt+d3rK5k/+rCtZ741BpnTOjPfsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmPM5e8t5jn0zWx48qPmd8Zt/G5Lob3jgmWZ/xi/T58BsvSpbR+J7C2omXvpVct019yfpzZ52e3nhven8x7zPF5+Kv2jgzue6UX6cvNd274c1k3Q7kPbtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulomhTNl8PHAfcCzQByyJiDslTQIeBGbRP23zVRGxo36t1tfv5/xbsr6pd1dh7fxffjW57qduHOy67+nro89Ot5a8Nvt7f3Jmct2eL6fPtf+j09cl6yeO2Zqsv7FnUvG296X//CYu83Xfa2koe/Ze4GsRcSpwLvAVSacBNwErImI2sKJ038xa1KBhj4hNEbGqdHsnsA6YASwAlpUetgy4sl5Nmln1Dukzu6RZwJnASmBaRGyC/n8QgPS1k8ysqYYcdknjgJ8CN0ZE9yGst1hSp6TOHtLXKzOz+hlS2CW10x/0H0fEw6XFmyVNL9WnA1vKrRsRSyKiIyI62hlVi57NrAKDhl2SgHuAdRHx3QGl5cCi0u1FwKO1b8/MamUop7jOA74IPC9pdWnZN4HbgIckXQu8CfxZfVpsfROnpT/VdF+RPk10wvLVyXrfnj3Juk75RGHt3Tnp02enHJE+xbWe2kf2Juvb/+q8ZH3qz19P1ns3vXPIPQ1ng4Y9In4HqKB8cW3bMbN68RF0Zplw2M0y4bCbZcJhN8uEw26WCYfdLBOKBk5rO0GT4hy15mjdhgc/k6xPGFs81j1uVPow4O496SMHd2wfl6wTRSOf/SZP2VlYmzauuAaDX0p68/vp3sb/Q7r+/nHF0y5vvzp9au/+/el90fj/HJusT747v1NkV8YKumN72T8Y79nNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0x4yuaSWX++JllXW/FLpdPS0z133VQ81gxw9MT0eHPbiPRY+FGji48B2LxrfHJd/evkZH3yw2uT9b6drybrqZHwUTvOSq7btbh4KmqA3ZcWX94boH33uYW1Cff/PrnucOQ9u1kmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WCZ/PbjaM+Hx2M3PYzXLhsJtlwmE3y4TDbpYJh90sEw67WSYGDbuk4yX9WtI6SS9IuqG0/BZJb0taXfqZX/92zaxSQ7l4RS/wtYhYJWk88KykJ0q170XEd+rXnpnVyqBhj4hNwKbS7Z2S1gEz6t2YmdXWIX1mlzQLOBNYWVp0vaQ1kpZKmliwzmJJnZI6e0hPk2Rm9TPksEsaB/wUuDEiuoEfACcBc+jf899Rbr2IWBIRHRHR0U56zjMzq58hhV1SO/1B/3FEPAwQEZsjYn9E9AF3A3Pr16aZVWso38YLuAdYFxHfHbB8+oCHfR5IX4bUzJpqKN/GzwO+CDwvaXVp2TeBhZLmAAFsAK6rS4dmVhND+Tb+d0C582Mfq307ZlYvPoLOLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTDjsZplw2M0y4bCbZaKhUzZLehd4Y8CiKcDWhjVwaFq1t1btC9xbpWrZ2wkRcUy5QkPD/rGNS50R0dG0BhJatbdW7QvcW6Ua1ZvfxptlwmE3y0Szw76kydtPadXeWrUvcG+VakhvTf3MbmaN0+w9u5k1iMNulommhF3SZZJelvSKpJua0UMRSRskPV+ahrqzyb0slbRF0toByyZJekLS+tLvsnPsNam3lpjGOzHNeFNfu2ZPf97wz+ySRgD/C1wCdAHPAAsj4sWGNlJA0gagIyKafgCGpD8EdgH3RcSnS8tuB7ZHxG2lfygnRsTXW6S3W4BdzZ7GuzRb0fSB04wDVwLX0MTXLtHXVTTgdWvGnn0u8EpEvBYR+4CfAAua0EfLi4ingO0HLV4ALCvdXkb/H0vDFfTWEiJiU0SsKt3eCXw4zXhTX7tEXw3RjLDPAN4acL+L1prvPYDHJT0raXGzmyljWkRsgv4/HmBqk/s52KDTeDfSQdOMt8xrV8n059VqRtjLTSXVSuN/8yLis8DlwFdKb1dtaIY0jXejlJlmvCVUOv15tZoR9i7g+AH3ZwIbm9BHWRGxsfR7C/AIrTcV9eYPZ9At/d7S5H4+0krTeJebZpwWeO2aOf15M8L+DDBb0omSRgJXA8ub0MfHSBpb+uIESWOBS2m9qaiXA4tKtxcBjzaxlwO0yjTeRdOM0+TXrunTn0dEw3+A+fR/I/8q8HfN6KGgr08Az5V+Xmh2b8AD9L+t66H/HdG1wGRgBbC+9HtSC/X2I+B5YA39wZrepN4uoP+j4RpgdelnfrNfu0RfDXndfLisWSZ8BJ1ZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMNulon/B/dHFE3l+ybXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[i])\n",
    "plt.title(\" Digit \" + str(y_test[i]) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A summary of the model\n",
    "We can output a summary of the model we have built with the summary function. This function gives us the layers in our model and their shape as well as parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n",
    "We should now save the model for use locally in our flask web server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('MyModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
